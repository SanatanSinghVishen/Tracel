# TRACEL

TRACEL is a small, event-driven system that simulates “network packets”, optionally scores them with a Python AI service, and streams them live to a SOC-style dashboard.

It’s organized as three apps:

- `dashboard/` (React + Vite + Tailwind): the UI.
- `server/` (Node + Express + Socket.IO): traffic simulation + APIs + realtime streaming.
- `ai-engine/` (Python): the `/predict` endpoint used by the simulator (optional).

## Quick Start (recommended)

This repo includes a root starter so you don’t have to open two terminals manually.

1. Install dependencies for dashboard + server:

```bash
npm run install:all
```

2. Start dashboard + server together:

```bash
npm run dev
```

3. Open the dashboard:

- `http://localhost:5173/` (Vite will use another port if busy)

### Default Ports

- Dashboard (Vite): `http://localhost:5173/`
- Server (Express + Socket.IO): `http://localhost:3001/`
- AI engine (optional): `http://127.0.0.1:5000/`

## What Runs Where

### Dashboard (`dashboard/`)

- Live views: globe, charts, forensics, settings, etc.
- Connects to the server using Socket.IO.
- Uses Clerk on the frontend (publishable key is required for auth flows).

### Server (`server/`)

- Optional MongoDB persistence (it will still work without Mongo).

### AI Engine (`ai-engine/`) (optional)

- Exposes `POST /predict` used by the simulator.
- If it’s not running, the server will still stream packets, but AI scoring will be degraded (safe defaults).

## Repository Layout

- `dashboard/`
  - `src/` – React app
  - `.env.example` – environment template
- `server/`
  - `index.js` – Express/Socket.IO app
  - `traffic_simulator.js` – traffic generator + AI call
  - `.env.example` – environment template
- `ai-engine/`
  - `train_model.py` – trains and writes `model.pkl`
  - `app.py` – Python API
  - `requirements.txt`

## Setup: Environment Variables

### Dashboard env (`dashboard/.env.local` recommended)

```env
VITE_SERVER_URL=http://localhost:3001
VITE_CLERK_PUBLISHABLE_KEY=pk_...
VITE_ADMIN_EMAIL=admin@example.com
```

- `VITE_SERVER_URL` must match the server port.
- `VITE_ADMIN_EMAIL` is a simple UI-side admin toggle (used to hide/show admin-only UI).
- Clerk keys:
  - Local dev typically uses `pk_test_...`.
  - Production deployments must use `pk_live_...`.

### Dashboard production env (for deployment)

Use hosting provider environment variables, or create a local production build file:

- Template: `dashboard/.env.production.example`
- Local prod build file: `dashboard/.env.production`

### Server env (`server/.env`)

```env
MONGO_URL=mongodb://localhost:27017/tracel
AI_PREDICT_URL=http://127.0.0.1:5000/predict

# Attack-mode tuning (0.0–1.0). Higher => more malicious packets during Attack Mode.
# Default (if unset): 0.6
ATTACK_MALICIOUS_RATIO=0.6

GROQ_API_KEY=...
GROQ_MODEL=llama-3.1-8b-instant

ADMIN_EMAIL=admin@example.com
ADMIN_USER_ID=

CLERK_JWKS_URL=

TRACEL_LOG_LEVEL=info
PORT=3001
```

Notes:

- If `MONGO_URL` is missing, the server runs “memory-only” (no persistence) but the dashboard still works.
- `ADMIN_EMAIL`/`ADMIN_USER_ID` controls server-side admin-only endpoints.
- If `CLERK_JWKS_URL` is set, the server verifies Clerk JWTs from `Authorization: Bearer <token>`.
- `TRACEL_LOG_LEVEL` can be `debug`, `info`, `warn`, or `error`.

## Deployment checklist (Clerk)

- Dashboard: set `VITE_CLERK_PUBLISHABLE_KEY=pk_live_...` in production.
- Dashboard: set `VITE_SERVER_URL` to your deployed server origin.
- Server: set `CLERK_JWKS_URL` to your Clerk production instance JWKS/well-known URL.
- Avoid deploying with Clerk development keys (`pk_test_...`) due to strict usage limits: https://clerk.com/docs/deployments/overview

### AI engine env (`ai-engine/`)

The AI engine runs with Python + `requirements.txt`. It reads `model.pkl` (generated by training).

Health check:

- `GET http://127.0.0.1:5000/health` — service up (model may load lazily)
- `GET http://127.0.0.1:5000/health?load=1` — forces model load and returns model metadata (threshold, path)

## Deploying AI Engine off Render (Option C)

If Render/Cloudflare rate-limiting blocks backend → AI calls, deploy `ai-engine/` somewhere else (container-based) and point the backend to it.

### Build & run locally (Docker)

From repo root:

```bash
docker build -t tracel-ai ./ai-engine
docker run --rm -p 5000:5000 -e PORT=5000 tracel-ai
```

Verify:

- `http://127.0.0.1:5000/` returns `{ ok: true, service: "ai-engine", ... }`
- `http://127.0.0.1:5000/health` returns `{ status: "running" }`

### Backend configuration

Set the server env var to the new AI base URL (include scheme):

```env
AI_SERVICE_URL=https://<your-ai-host>
```

Examples:

- Fly.io: `AI_SERVICE_URL=https://tracel-ai.fly.dev`
- Railway: `AI_SERVICE_URL=https://tracel-ai-production.up.railway.app`
- Azure Container Apps: `AI_SERVICE_URL=https://tracel-ai.<region>.azurecontainerapps.io`

After deploy, verify from backend:

- `GET /api/ai/status?probe=1` should show `probe.root.status: 200` and `okSignature: true`.

## Running Each App Separately (manual)

### 1) Server

```bash
cd server
npm install
npm run dev
```

Server: `http://localhost:3001/`

### 2) Dashboard

```bash
cd dashboard
npm install
npm run dev
```

Dashboard: `http://localhost:5173/`

### 3) AI engine (optional)

```bash
cd ai-engine

python -m venv venv

# PowerShell
./venv/Scripts/Activate.ps1

pip install -r requirements.txt

# train once (creates/updates model.pkl)
python train_model.py

python app.py
```

AI engine: `http://127.0.0.1:5000/`

## Root Scripts

From the repo root:

- `npm run install:all` — installs dashboard + server deps.
- `npm run dev` — runs dashboard + server together.
- `npm run dev:dashboard` — dashboard only.
- `npm run dev:server` — server only.
- `npm run lint` — dashboard ESLint.
- `npm run build` — dashboard production build.

## VS Code Tasks

Use “Run Task” in VS Code:

- `dev: all`
- `dev: dashboard`
- `dev: server`

## Troubleshooting

### “Port already in use” (EADDRINUSE)

- Server uses port `3001` (configurable via `PORT`).
- Dashboard uses port `5173` (Vite will automatically pick `5174`, `5175`, etc.).

On Windows PowerShell you can find and kill by port:

```powershell
Get-NetTCPConnection -LocalPort 3001 | Select-Object -ExpandProperty OwningProcess -Unique
Stop-Process -Id <PID> -Force
```

### Dashboard shows “no data” / not connecting

- Confirm the server is running.
- Confirm `VITE_SERVER_URL` matches the server URL and port.
- Check the browser console and the server terminal output.

### Clerk: “Failed to load Clerk” / `failed_to_load_clerk_js_timeout`

If the browser can’t load `clerk.browser.js` (often due to network filtering of `*.clerk.accounts.dev`), Clerk auth flows will fail.

- First, try a hard refresh and check DevTools → Network for the failed script request.
- Workaround: set `VITE_CLERK_JS_URL` to an alternate hosted copy of Clerk JS.
  - Example: `https://cdn.jsdelivr.net/npm/@clerk/clerk-js@5/dist/clerk.browser.js`
  - Put it in `dashboard/.env.local` (dev) or your hosting env vars (prod).

### MongoDB errors

- If you don’t want Mongo at all, remove `MONGO_URL` from `server/.env`.
- If using MongoDB Atlas, ensure your IP is whitelisted and credentials are correct.

## Validation: Attack Mode realism

There’s a small validator script that toggles Attack Mode and measures anomaly rates.

```bash
node server/tools/validate_attack_mode.js qa-sim
```

Useful env vars for the validator (optional):

- `AI_URL` (default `http://127.0.0.1:5000`) — AI engine base URL
- `SAMPLE_SECONDS_ON`, `SAMPLE_SECONDS_OFF` — how long to sample each phase
- `MIN_PACKETS_ON`, `MIN_PACKETS_OFF` — minimum packets to collect per phase
- `MAX_WAIT_SECONDS_ON`, `MAX_WAIT_SECONDS_OFF` — maximum wait for min packets
- `SETTLE_MS` — delay after toggling before starting the measurement window

Example (more stable OFF baseline):

```powershell
$env:SAMPLE_SECONDS_ON=10
$env:MIN_PACKETS_ON=80
$env:MAX_WAIT_SECONDS_ON=40
$env:SAMPLE_SECONDS_OFF=240
$env:MIN_PACKETS_OFF=120
$env:MAX_WAIT_SECONDS_OFF=720
$env:SETTLE_MS=800
node server/tools/validate_attack_mode.js qa-sim
```

### AI engine offline

- If `AI_PREDICT_URL` points to a non-running service, the server still streams packets, but AI scoring is reduced.

## Clean Reset (common)

If you deleted `node_modules` or dependencies got corrupted:

```bash
npm run install:all
npm run dev
```
